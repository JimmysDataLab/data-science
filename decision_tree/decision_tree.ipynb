{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9d57cb",
   "metadata": {},
   "source": [
    "* Pure python implementation of decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac055b",
   "metadata": {},
   "source": [
    "* Decision Tree is a binary tree that recursively splits a dataset until it is left with pure leaf nodes.\n",
    "* Its a greedy algorithm\n",
    "\n",
    "$$\n",
    "H(S) = - \\sum_{i=1}^{n} p(x_i) \\log_2 p(x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "IG(T, A) = H(T) - \\sum_{v \\in \\text{Values}(A)} \\frac{|T_v|}{|T|} H(T_v)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f5ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select a feature\n",
    "# 2. Select feature value randomly from range\n",
    "# 3. Calculate entropy (purity of sample)\n",
    "#    a. Proportion of +(ve) examples -> p =  count(feature) groupby target filter target == 1 / sum(feature)\n",
    "#    b. Proportion of -(ve) examples -> n =  1 - p\n",
    "#    c. entropy = -plog2(p) - nlog2(n)\n",
    "#    d. entropy (general) = sigma(-Pnlog2(Pn))\n",
    "# 4. Split feature according to entropy and do 3. for each split (binary tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22ec0d",
   "metadata": {},
   "source": [
    "### Doubts\n",
    "\n",
    "#### What are the stopping conditions for splitting\n",
    "\n",
    "* Maximum Depth Reached:\n",
    "\n",
    "    * The tree is allowed to grow only up to a predefined maximum depth. Once this limit is reached, the node is not split further.\n",
    "* Minimum Samples for a Split:\n",
    "\n",
    "    * A node is split only if it contains more than a certain number of samples. If the number of samples in a node falls below this threshold, the split will not occur.\n",
    "* Minimum Samples in a Leaf Node:\n",
    "\n",
    "    * After splitting, the resulting child nodes must have at least a minimum number of samples. If this condition is violated, no split occurs.\n",
    "* Impurity Improvement Below a Threshold:\n",
    "\n",
    "    * Splitting is stopped when the improvement in the chosen impurity metric (like Gini Impurity or Entropy) is less than a predefined threshold. If the split does not significantly improve the purity of the node, it is not performed.\n",
    "* All Features Used:\n",
    "\n",
    "    * If all features have been used up or if no further features provide better splits, the process stops.\n",
    "* Pure Nodes:\n",
    "\n",
    "    * If all the samples in a node belong to the same class, the node is considered \"pure,\" and further splitting is unnecessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05131989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d386497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Convert to a pandas DataFrame for easier analysis\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "# Display the first few rows\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef20bf4",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e20a25",
   "metadata": {},
   "source": [
    "### Akhil's version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773f174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self,X: pd.DataFrame = None, y: pd.Series = None ,\\\n",
    "                 feature: str = None, threshold: float = None , \\\n",
    "                 left: 'Node' = None , right: 'Node' = None, \\\n",
    "                 entropy_node: float = None, entropy_left_child: float = None ,\\\n",
    "                 length_node: int = None, length_left_child: int = None, length_right_child: int = None,\\\n",
    "                 w_left: float = None, w_right: float = None,\\\n",
    "                 entropy_right_child: float = None, entropy_children: float = None,path: str = None, \\\n",
    "                 max_info_gain: float = -math.inf, value: float = None, current_depth: int = 0):\n",
    "        \n",
    "        # Basic Node Params\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.feature = feature      \n",
    "        self.threshold = threshold  \n",
    "        self.left = left            \n",
    "        self.right = right\n",
    "        self.current_depth = current_depth\n",
    "        self.path = path\n",
    "            \n",
    "        # Information Gain Params\n",
    "        self.entropy_node = entropy_node\n",
    "        self.entropy_left_child = entropy_left_child\n",
    "        self.entropy_right_child = entropy_right_child\n",
    "        self.entropy_children = entropy_children\n",
    "        self.length_node = length_node\n",
    "        self.length_left_child = length_left_child\n",
    "        self.length_right_child = length_right_child\n",
    "        self.w_left = w_left\n",
    "        self.w_right = w_right\n",
    "        #self.info_gain = info_gain\n",
    "        self.max_info_gain = max_info_gain\n",
    "        \n",
    "        # Leaf Params\n",
    "        self.value = value\n",
    "        \n",
    "        # Print Param\n",
    "        self.indent = \"----\"\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        indent = self.indent * self.current_depth\n",
    "        \n",
    "        if self.current_depth == 0:\n",
    "            rep = f\"|{indent}|\\U0001F914{self.feature} <= {self.threshold}    \\U00002B06{round(self.max_info_gain,2)}\"\n",
    "        \n",
    "        else:\n",
    "            if self.value is not None:\n",
    "                rep = f\"|{indent}|\\U0001F343{self.path}: {self.value}\"\n",
    "                \n",
    "            else:\n",
    "                rep = f\"|{indent}|\\U0001F914{self.path}:{self.feature} <= {self.threshold}    \\U00002B06{round(self.max_info_gain,2)}\" \n",
    "        \n",
    "        return rep\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de39db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    \n",
    "    \n",
    "    def __init__(self, min_samples_split = 3, max_depth = 15, min_info_gain = .001):\n",
    "\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.min_info_gain = min_info_gain\n",
    "        \n",
    "        self.root = None\n",
    "        \n",
    "    \n",
    "    def build_tree(self, node):\n",
    "\n",
    "        \n",
    "        if len(node.y) >= self.min_samples_split and node.current_depth <= self.max_depth:\n",
    "            \n",
    "            left_X, left_y, right_X, right_y = self.get_best_split(node)\n",
    "            if node.max_info_gain > self.min_info_gain :\n",
    "                node.left = Node(left_X, left_y, current_depth = node.current_depth + 1, path = 'Left')\n",
    "                node.right = Node(right_X, right_y, current_depth = node.current_depth + 1,path = 'Right')\n",
    "                self.build_tree(node.left)\n",
    "                self.build_tree(node.right)\n",
    "            else:\n",
    "                node.value = node.y.mode()[0]\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            node.value = node.y.mode()[0]\n",
    "\n",
    "            \n",
    "         \n",
    "            \n",
    "    def get_best_split(self, node):\n",
    "\n",
    "        X, y = node.X, node.y\n",
    "\n",
    "        #node.info_gain = -math.inf\n",
    "        \n",
    "        for feature in X.columns:\n",
    "            unique_values = X[feature].unique()\n",
    "            for threshold in unique_values:\n",
    "                # Split \n",
    "                left_y,right_y = y[X[feature] <= threshold], y[X[feature] > threshold]\n",
    "                \n",
    "                # Implementing a check for null left or right\n",
    "                if len(left_y) > 0 and len(right_y) > 0: # Don't consider edge of X.feature\n",
    "                    \n",
    "                    entropy_left, entropy_right, length_node, length_left, \\\n",
    "                    length_right, w_left, w_right, entropy_children, \\\n",
    "                    gain = self.info_gain(left_y,right_y, node)\n",
    "\n",
    "                    if gain > node.max_info_gain:\n",
    "                        node.max_info_gain = gain\n",
    "                        node.feature = feature\n",
    "                        node.threshold = threshold\n",
    "                        node.entropy_left_child = entropy_left\n",
    "                        node.entropy_right_child = entropy_right\n",
    "                        node.length_node = length_node\n",
    "                        node.length_left_child = length_left\n",
    "                        node.length_right_child = length_right\n",
    "                        node.w_left = w_left\n",
    "                        node.w_right = w_right\n",
    "                        node.entropy_children = entropy_children\n",
    "     \n",
    "        \n",
    "\n",
    "        left_X = X[X[node.feature] <= node.threshold]\n",
    "        left_y = y[X[node.feature] <= node.threshold]\n",
    "        right_X = X[X[node.feature] > node.threshold]\n",
    "        right_y = y[X[node.feature] > node.threshold]\n",
    "        \n",
    "\n",
    "        return left_X, left_y, right_X, right_y\n",
    "    \n",
    "                \n",
    "    def info_gain(self, left_y:pd.Series, right_y:pd.Series, node: 'Node') -> float:\n",
    "\n",
    "        node.entropy_node = self.entropy(node.y)\n",
    "        entropy_left = self.entropy(left_y)\n",
    "        entropy_right = self.entropy(right_y)\n",
    "        length_node = len(node.y)\n",
    "        length_left = len(left_y)\n",
    "        length_right = len(right_y)\n",
    "        w_left = length_left/length_node\n",
    "        w_right = length_right/length_node\n",
    "        entropy_children = w_left * entropy_left + w_right * entropy_right\n",
    "        gain = node.entropy_node - entropy_children\n",
    "\n",
    "        return entropy_left, entropy_right, length_node, length_left, \\\n",
    "                    length_right, w_left, w_right, entropy_children, \\\n",
    "                    gain\n",
    "    \n",
    "    \n",
    "    def entropy(self, y:pd.Series) -> float:\n",
    "    \n",
    "        prob = y.value_counts(normalize = True).reset_index()\n",
    "\n",
    "        return sum([-p * math.log2(p) for p in prob.proportion])\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.root = Node(X, y, path = 'root')\n",
    "        #print(self.root.max_info_gain)\n",
    "        self.build_tree(self.root)\n",
    "        \n",
    "\n",
    "    def print_tree(self, node = None):\n",
    "        \n",
    "        if node == None:\n",
    "            node = self.root\n",
    "            \n",
    "        if node.value is not None:\n",
    "            print(f\"{node.current_depth - 1}->{node.path}->{node.current_depth}:`Leaf`[[{node.value}]]\")\n",
    "            \n",
    "        else:\n",
    "            if node.current_depth == 0:\n",
    "                print(f\"{node.current_depth}->{node.path}->{node.current_depth}:`Decision`({node.feature})[{node.threshold}]\")\n",
    "                self.print_tree(node.left)\n",
    "                self.print_tree(node.right)\n",
    "            else:\n",
    "                print(f\"{node.current_depth - 1}->{node.path}->{node.current_depth}:`Decision`({node.feature})[{node.threshold}]\")\n",
    "                self.print_tree(node.left)\n",
    "                self.print_tree(node.right)\n",
    "                \n",
    "                \n",
    "    \n",
    "    def inorder_traversal(self, node = None):\n",
    "        \n",
    "        if not node:\n",
    "            node = self.root\n",
    "        \n",
    "        if node.left:\n",
    "            self.inorder_traversal(node.left)\n",
    "        print(node)\n",
    "        if node.right:\n",
    "            self.inorder_traversal(node.right)\n",
    "            \n",
    "            \n",
    "            \n",
    "    def preorder_traversal(self, node = None):\n",
    "        \n",
    "        if not node:\n",
    "            node = self.root\n",
    "        \n",
    "        print(node)\n",
    "        if node.left:\n",
    "            self.preorder_traversal(node.left)\n",
    "   \n",
    "        if node.right:\n",
    "            self.preorder_traversal(node.right)\n",
    "            \n",
    "            \n",
    "    def postorder_traversal(self, node = None):\n",
    "        \n",
    "        if not node:\n",
    "            node = self.root\n",
    "  \n",
    "        if node.left:\n",
    "            self.postorder_traversal(node.left)\n",
    "   \n",
    "        if node.right:\n",
    "            self.postorder_traversal(node.right)\n",
    "        print(node)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb6ab9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris_df.iloc[:,:-1]\n",
    "y = iris_df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 41)\n",
    "\n",
    "tree = DecisionTreeClassifier(min_samples_split = 10, max_depth = 5,min_info_gain = .1)\n",
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8e8c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||🤔petal length (cm) <= 1.9    ⬆0.93\n",
      "|----|🍃Left: 0\n",
      "|----|🤔Right:petal width (cm) <= 1.5    ⬆0.77\n",
      "|--------|🤔Left:petal length (cm) <= 4.9    ⬆0.18\n",
      "|------------|🍃Left: 1\n",
      "|------------|🍃Right: 2\n",
      "|--------|🤔Right:petal length (cm) <= 5.0    ⬆0.12\n",
      "|------------|🍃Left: 2\n",
      "|------------|🍃Right: 2\n"
     ]
    }
   ],
   "source": [
    "tree.preorder_traversal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11063384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node entropy: 1.5846619079379884\n",
      "left entropy: 0.0\n",
      "right entropy: 0.9998844148717589\n",
      "left length: 41\n",
      "right lenght: 79\n",
      "node lenght: 120\n",
      "left weight: 0.3416666666666667\n",
      "right weight: 0.6583333333333333\n",
      "children entropy: 0.6582572397905746\n",
      "information gain: 0.9264046681474138\n",
      "node value: None\n"
     ]
    }
   ],
   "source": [
    "def validate(node):\n",
    "    print('node entropy:',node.entropy_node)\n",
    "    print('left entropy:',node.entropy_left_child)\n",
    "    print('right entropy:',node.entropy_right_child)\n",
    "    print('left length:',node.length_left_child)\n",
    "    print('right lenght:',node.length_right_child)\n",
    "    print('node lenght:',node.length_node)\n",
    "    print('left weight:',node.w_left)\n",
    "    print('right weight:',node.w_right)\n",
    "    print('children entropy:',node.entropy_children)\n",
    "    print('information gain:',node.max_info_gain)\n",
    "    print('node value:',node.value)\n",
    "\n",
    "validate(tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c3be35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node entropy: 0.0\n",
      "left entropy: 0.0\n",
      "right entropy: 0.0\n",
      "left length: 30\n",
      "right lenght: 11\n",
      "node lenght: 41\n",
      "left weight: 0.7317073170731707\n",
      "right weight: 0.2682926829268293\n",
      "children entropy: 0.0\n",
      "information gain: 0.0\n",
      "node value: 0\n"
     ]
    }
   ],
   "source": [
    "validate(tree.root.left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4c821fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node entropy: 0.9998844148717589\n",
      "left entropy: 0.17556502585750278\n",
      "right entropy: 0.2811937964320427\n",
      "left length: 38\n",
      "right lenght: 41\n",
      "node lenght: 79\n",
      "left weight: 0.4810126582278481\n",
      "right weight: 0.5189873417721519\n",
      "children entropy: 0.23038502071264375\n",
      "information gain: 0.7694993941591152\n",
      "node value: None\n"
     ]
    }
   ],
   "source": [
    "validate(tree.root.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00ad7b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node entropy: 0.17556502585750278\n",
      "left entropy: 0.0\n",
      "right entropy: 0.0\n",
      "left length: 37\n",
      "right lenght: 1\n",
      "node lenght: 38\n",
      "left weight: 0.9736842105263158\n",
      "right weight: 0.02631578947368421\n",
      "children entropy: 0.0\n",
      "information gain: 0.17556502585750278\n",
      "node value: None\n"
     ]
    }
   ],
   "source": [
    "validate(tree.root.right.left)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
