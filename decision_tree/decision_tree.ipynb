{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9d57cb",
   "metadata": {},
   "source": [
    "* Pure python implementation of decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d002c",
   "metadata": {},
   "source": [
    "* Decision Tree is a binary tree that recursively splits a dataset until it is left with pure leaf nodes.\n",
    "* Its a greedy algorithm\n",
    "\n",
    "$$\n",
    "H(S) = - \\sum_{i=1}^{n} p(x_i) \\log_2 p(x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "IG(T, A) = H(T) - \\sum_{v \\in \\text{Values}(A)} \\frac{|T_v|}{|T|} H(T_v)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select a feature\n",
    "# 2. Select feature value randomly from range\n",
    "# 3. Calculate entropy (purity of sample)\n",
    "#    a. Proportion of +(ve) examples -> p =  count(feature) groupby target filter target == 1 / sum(feature)\n",
    "#    b. Proportion of -(ve) examples -> n =  1 - p\n",
    "#    c. entropy = -plog2(p) - nlog2(n)\n",
    "#    d. entropy (general) = sigma(-Pnlog2(Pn))\n",
    "# 4. Split feature according to entropy and do 3. for each split (binary tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d386497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Convert to a pandas DataFrame for easier analysis\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "# Display the first few rows\n",
    "#print(iris_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82854d51",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision(feature: np.ndarray, target: np.ndarray) -> float:\n",
    "    \n",
    "    node_entropy = calcuate_entropy(feature,target)\n",
    "    random_split = np.random.choice(feature_vector)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "feature = SAMPLE_DATA.x1.values\n",
    "target = SAMPLE_DATA.y.values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(feature,target):\n",
    "\n",
    "    p = len(feature[target == True])/ len(feature)\n",
    "    entropy = -(p*math.log2(p) - (1-p)*math.log2(1-p)) \n",
    "    \n",
    "    return entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_entropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcdc8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(parent = None, left_child = None, right_child = None):\n",
    "        self.parent = None\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        \n",
    "class Tree()\n",
    "\n",
    "    def __init__(depth=0, root = None):\n",
    "        self.depth = 0\n",
    "        self.root = None\n",
    "        \n",
    "    def grow_tree\n",
    "    \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
