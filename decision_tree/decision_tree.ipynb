{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0e7ff0",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "* How to handle missing values in X and Y\n",
    "    * For Categorical Xs and Ys, missing can be treated as separate category\n",
    "    * For Numerical, ?\n",
    "* How to handle numerical and catagorical in X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d57cb",
   "metadata": {},
   "source": [
    "## Pure python implementation of decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8abc3",
   "metadata": {},
   "source": [
    "| Aspect                | Shannon Entropy                              | Gini Index                                      |\n",
    "|-----------------------|----------------------------------------------|-------------------------------------------------|\n",
    "| **Range of Values**    | Ranges from **0** to **log2(n)** (for \\(n\\) classes) | Ranges from **0** to **1**                           |\n",
    "| **Complexity**         | More computationally intensive (requires logarithmic computation) | Less computationally expensive (squared terms only) |\n",
    "| **Interpretation**     | Measures uncertainty or disorder in the dataset | Measures the probability of misclassification      |\n",
    "| **Bias Towards Splits**| Tends to favor splits that result in more balanced class distributions | Tends to favor larger partitions or more pure splits |\n",
    "| **Behavior**           | Sensitive to changes in small probabilities  | Less sensitive to small class differences           |\n",
    "| **Used In**            | Algorithms like **ID3**, **C4.5**            | Used in **CART** algorithm                         |\n",
    "| **Theoretical Basis**  | Based on **information theory**              | Based on the **probability of misclassification**  |\n",
    "| **Practical Speed**    | Slightly slower due to logarithmic calculation | Faster due to simple squared terms                |\n",
    "| **Preference for Splits** | Can result in more balanced splits         | Often results in purer splits in larger partitions |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67600cf8",
   "metadata": {},
   "source": [
    "### Shannon Entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac055b",
   "metadata": {},
   "source": [
    "* Decision Tree is a binary tree that recursively splits a dataset until it is left with pure leaf nodes.\n",
    "* Its a greedy algorithm\n",
    "\n",
    "$$\n",
    "H(S) = - \\sum_{i=1}^{n} p(x_i) \\log_2 p(x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "IG(T, A) = H(T) - \\sum_{v \\in \\text{Values}(A)} \\frac{|T_v|}{|T|} H(T_v)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f5ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Select a feature\n",
    "# 2. Select feature value randomly from range\n",
    "# 3. Calculate entropy (purity of sample)\n",
    "#    a. Proportion of +(ve) examples -> p =  count(feature) groupby target filter target == 1 / sum(feature)\n",
    "#    b. Proportion of -(ve) examples -> n =  1 - p\n",
    "#    c. entropy = -plog2(p) - nlog2(n)\n",
    "#    d. entropy (general) = sigma(-Pnlog2(Pn))\n",
    "# 4. Split feature according to entropy and do 3. for each split (binary tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22ec0d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### What are the stopping conditions for splitting a node ?\n",
    "\n",
    "* Maximum Depth Reached:\n",
    "\n",
    "    * The tree is allowed to grow only up to a predefined maximum depth. Once this limit is reached, the node is not split further.\n",
    "* Minimum Samples for a Split:\n",
    "\n",
    "    * A node is split only if it contains more than a certain number of samples. If the number of samples in a node falls below this threshold, the split will not occur.\n",
    "* Minimum Samples in a Leaf Node:\n",
    "\n",
    "    * After splitting, the resulting child nodes must have at least a minimum number of samples. If this condition is violated, no split occurs.\n",
    "* Impurity Improvement Below a Threshold:\n",
    "\n",
    "    * Splitting is stopped when the improvement in the chosen impurity metric (like Gini Impurity or Entropy) is less than a predefined threshold. If the split does not significantly improve the purity of the node, it is not performed.\n",
    "* All Features Used:\n",
    "\n",
    "    * If all features have been used up or if no further features provide better splits, the process stops.\n",
    "* Pure Nodes:\n",
    "\n",
    "    * If all the samples in a node belong to the same class, the node is considered \"pure,\" and further splitting is unnecessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05131989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d386497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Convert to a pandas DataFrame for easier analysis\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "# Display the first few rows\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef20bf4",
   "metadata": {},
   "source": [
    "### Base Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773f174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self,X: pd.DataFrame = None, y: pd.Series = None ,\\\n",
    "                 feature: str = None, threshold: float = None , \\\n",
    "                 left: 'Node' = None , right: 'Node' = None, \\\n",
    "                 entropy_node: float = None, entropy_left_child: float = None ,\\\n",
    "                 length_node: int = None, length_left_child: int = None, length_right_child: int = None,\\\n",
    "                 w_left: float = None, w_right: float = None,\\\n",
    "                 entropy_right_child: float = None, entropy_children: float = None,path: str = None, \\\n",
    "                 max_info_gain: float = -math.inf, value: float = None, current_depth: int = 0):\n",
    "        \n",
    "        # Basic Node Params\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.feature = feature      \n",
    "        self.threshold = threshold  \n",
    "        self.left = left            \n",
    "        self.right = right\n",
    "        self.current_depth = current_depth\n",
    "        self.path = path\n",
    "            \n",
    "        # Information Gain Params\n",
    "        self.entropy_node = entropy_node\n",
    "        self.entropy_left_child = entropy_left_child\n",
    "        self.entropy_right_child = entropy_right_child\n",
    "        self.entropy_children = entropy_children\n",
    "        self.length_node = length_node\n",
    "        self.length_left_child = length_left_child\n",
    "        self.length_right_child = length_right_child\n",
    "        self.w_left = w_left\n",
    "        self.w_right = w_right\n",
    "        #self.info_gain = info_gain\n",
    "        self.max_info_gain = max_info_gain\n",
    "        \n",
    "        # Leaf Params\n",
    "        self.value = value\n",
    "        \n",
    "        # Print Param\n",
    "        self.indent = \"----\"\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        indent = self.indent * self.current_depth\n",
    "        \n",
    "        if self.current_depth == 0:\n",
    "            rep = f\"|{indent}|\\U0001F914{self.feature} <= {self.threshold}    \\U00002B06{round(self.max_info_gain,2)}\"\n",
    "        \n",
    "        else:\n",
    "            if self.value is not None:\n",
    "                rep = f\"|{indent}|\\U0001F343{self.path}: {self.value}\"\n",
    "                \n",
    "            else:\n",
    "                rep = f\"|{indent}|\\U0001F914{self.path}:{self.feature} <= {self.threshold}    \\U00002B06{round(self.max_info_gain,2)}\" \n",
    "        \n",
    "        return rep\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d6299",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de39db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    \n",
    "    \n",
    "    def __init__(self, min_samples_split = 10, max_depth = 15, \\\n",
    "                 min_samples_leaf = 5, min_info_gain = .001):\n",
    "\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.min_samples_leaf = min_samples_leaf if \\\n",
    "                            min_samples_leaf <= min_samples_split // 2 else min_samples_split // 2\n",
    "        \n",
    "        self.min_info_gain = min_info_gain\n",
    "        self.root = None\n",
    "        \n",
    "    \n",
    "    def build_tree(self, node):\n",
    "\n",
    "        \n",
    "        \n",
    "        # STOP CONDITIONS\n",
    "        # node.current_depth > self.max_depth (before split)\n",
    "        # len(node.y) < self.min_samples_split(before split) [min samples for split]\n",
    "        # len(node.left.y) or len(node.right.y) < self.min_leaf_split (after split) [min samples in split]\n",
    "        # node.max_info_gain < self.min_info_gain (after split) [if best split info gain is worse than min info gain]\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            if node.current_depth > self.max_depth or len(node.y) < self.min_samples_split:\n",
    "                node.value = node.y.mode()[0]\n",
    "                #node.value = node.y.value_counts()\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                self.get_best_split(node)\n",
    "                if node.feature and node.max_info_gain >= self.min_info_gain : # Found acceptable split\n",
    "                    X_left, X_right , y_left, y_right = self.split(node)\n",
    "                    node.left = Node(X_left, y_left, current_depth = node.current_depth + 1, path = 'Left')\n",
    "                    node.right = Node(X_right, y_right, current_depth = node.current_depth + 1,path = 'Right')\n",
    "                    self.build_tree(node.left)\n",
    "                    self.build_tree(node.right)              \n",
    "                    break\n",
    "                else:\n",
    "                    node.value = node.y.mode()[0]\n",
    "                    #node.value = node.y.value_counts()\n",
    "                    break\n",
    "                    \n",
    "            print(\"Found some edge bug\")\n",
    "            break\n",
    "\n",
    "            \n",
    "                \n",
    "    def split(self,node):\n",
    "        \n",
    "        X_left = node.X[node.X[node.feature] <= node.threshold]\n",
    "        X_right = node.X[node.X[node.feature] > node.threshold]\n",
    "        y_left = node.y[node.X[node.feature] <= node.threshold]\n",
    "        y_right = node.y[node.X[node.feature] > node.threshold]\n",
    "        \n",
    "        return X_left, X_right , y_left, y_right\n",
    "    \n",
    "    \n",
    "            \n",
    "    def get_best_split(self, node):\n",
    "\n",
    "        X, y = node.X, node.y\n",
    "\n",
    "\n",
    "        \n",
    "        for feature in X.columns:\n",
    "            unique_values = X[feature].unique()\n",
    "            for threshold in unique_values: # Remove nans\n",
    "                # Split \n",
    "                left_y,right_y = y[X[feature] <= threshold], y[X[feature] > threshold]\n",
    "                \n",
    "                # Implementing a check for null left or right\n",
    "                if len(left_y) >= self.min_samples_leaf and len(right_y) >= self.min_samples_leaf: \n",
    "                    \n",
    "                    entropy_left, entropy_right, length_node, length_left, \\\n",
    "                    length_right, w_left, w_right, entropy_children, \\\n",
    "                    gain = self.info_gain(left_y,right_y, node)\n",
    "\n",
    "                    if gain > node.max_info_gain:\n",
    "                        node.max_info_gain = gain\n",
    "                        node.feature = feature\n",
    "                        node.threshold = threshold\n",
    "                        node.entropy_left_child = entropy_left\n",
    "                        node.entropy_right_child = entropy_right\n",
    "                        node.length_node = length_node\n",
    "                        node.length_left_child = length_left\n",
    "                        node.length_right_child = length_right\n",
    "                        node.w_left = w_left\n",
    "                        node.w_right = w_right\n",
    "                        node.entropy_children = entropy_children\n",
    "     \n",
    "\n",
    "\n",
    "    \n",
    "                \n",
    "    def info_gain(self, left_y:pd.Series, right_y:pd.Series, node: 'Node') -> float:\n",
    "\n",
    "        node.entropy_node = self.entropy(node.y)\n",
    "        entropy_left = self.entropy(left_y) \n",
    "        entropy_right = self.entropy(right_y)\n",
    "        length_node = len(node.y)\n",
    "        length_left = len(left_y)\n",
    "        length_right = len(right_y)\n",
    "        w_left = length_left/length_node\n",
    "        w_right = length_right/length_node\n",
    "        entropy_children = w_left * entropy_left + w_right * entropy_right\n",
    "        gain = node.entropy_node - entropy_children\n",
    "\n",
    "        return entropy_left, entropy_right, length_node, length_left, \\\n",
    "                    length_right, w_left, w_right, entropy_children, \\\n",
    "                    gain\n",
    "    \n",
    "    \n",
    "    def entropy(self, y:pd.Series) -> float:\n",
    "    \n",
    "        prob = y.value_counts(normalize = True).reset_index()\n",
    "\n",
    "        return sum([-p * math.log2(p) for p in prob.proportion])\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        self.root = Node(X, y, path = 'root')\n",
    "        #print(self.root.max_info_gain)\n",
    "        self.build_tree(self.root)\n",
    "        \n",
    "    \n",
    "    def _predict(self,x: pd.Series, node = None):\n",
    "        \n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        \n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        else:\n",
    "            if x[node.feature] <= node.threshold:\n",
    "                return self._predict(x,node.left)\n",
    "            else:\n",
    "                return self._predict(x,node.right)\n",
    "            \n",
    "\n",
    "            \n",
    "    def predict(self,X: pd.DataFrame):\n",
    "        \n",
    "        prediction = []\n",
    "        for i in range(len(X)):\n",
    "            prediction.append(self._predict(X.iloc[i,:]))\n",
    "            \n",
    "        return pd.DataFrame({'y_pred':prediction})\n",
    "            \n",
    "         \n",
    "                \n",
    "    \n",
    "    def inorder_traversal(self, node = None):\n",
    "        \n",
    "        if not node:\n",
    "            node = self.root\n",
    "        \n",
    "        if node.left:\n",
    "            self.inorder_traversal(node.left)\n",
    "        print(node)\n",
    "        if node.right:\n",
    "            self.inorder_traversal(node.right)\n",
    "            \n",
    "            \n",
    "            \n",
    "    def preorder_traversal(self, node = None):\n",
    "        \n",
    "        if not node:\n",
    "            node = self.root\n",
    "        \n",
    "        print(node)\n",
    "        if node.left:\n",
    "            self.preorder_traversal(node.left)\n",
    "   \n",
    "        if node.right:\n",
    "            self.preorder_traversal(node.right)\n",
    "            \n",
    "            \n",
    "    def postorder_traversal(self, node = None):\n",
    "        \n",
    "        if not node:\n",
    "            node = self.root\n",
    "  \n",
    "        if node.left:\n",
    "            self.postorder_traversal(node.left)\n",
    "   \n",
    "        if node.right:\n",
    "            self.postorder_traversal(node.right)\n",
    "        print(node)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "05c57025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris_df.iloc[:,:-1]\n",
    "y = iris_df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 41)\n",
    "\n",
    "tree = DecisionTreeClassifier(min_samples_split = 2, max_depth = 15,min_info_gain = .001)\n",
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c87acadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "||🤔petal length (cm) <= 1.9    ⬆0.93\n",
      "|----|🍃Left: 0\n",
      "|----|🤔Right:petal width (cm) <= 1.5    ⬆0.77\n",
      "|--------|🤔Left:petal length (cm) <= 4.9    ⬆0.18\n",
      "|------------|🍃Left: 1\n",
      "|------------|🍃Right: 2\n",
      "|--------|🤔Right:petal length (cm) <= 5.0    ⬆0.12\n",
      "|------------|🤔Left:sepal width (cm) <= 2.8    ⬆0.47\n",
      "|----------------|🍃Left: 2\n",
      "|----------------|🤔Right:sepal length (cm) <= 5.9    ⬆0.25\n",
      "|--------------------|🍃Left: 1\n",
      "|--------------------|🤔Right:sepal length (cm) <= 6.0    ⬆1.0\n",
      "|------------------------|🍃Left: 2\n",
      "|------------------------|🍃Right: 1\n",
      "|------------|🍃Right: 2\n"
     ]
    }
   ],
   "source": [
    "tree.preorder_traversal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cf87f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "87513ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(prediction_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "77035e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6. , 6.4, 7.7, 6.1, 6.8, 6.3, 6.5, 5.1, 4.4, 5. , 4.8, 4.9, 4.5,\n",
       "       5.5, 6.9, 4.7, 5.6, 5.8])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['sepal length (cm)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad13048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate(node):\n",
    "#     print('node entropy:',node.entropy_node)\n",
    "#     print('left entropy:',node.entropy_left_child)\n",
    "#     print('right entropy:',node.entropy_right_child)\n",
    "#     print('left length:',node.length_left_child)\n",
    "#     print('right length:',node.length_right_child)\n",
    "#     print('node lenght:',node.length_node)\n",
    "#     print('left weight:',node.w_left)\n",
    "#     print('right weight:',node.w_right)\n",
    "#     print('children entropy:',node.entropy_children)\n",
    "#     print('information gain:',node.max_info_gain)\n",
    "#     print('node value:',node.value)\n",
    "\n",
    "# validate(tree.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757d6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "data-science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
